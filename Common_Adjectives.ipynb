{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the most commonly used adjectives in our articles\n",
    "Here we use NLTK to identify commonly used adjectives in our articles. This will be helpful in future when looking to increase the coverage of our lexicon. We can use this to find commonly used adjectives that are not contained in Loughran & McDonald's lexicon.\n",
    "\n",
    "First we read our articles from CSV, and then drop all columns but 'text', as all we're concerned with here is the article text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decathlon’s Dublin opening, tobacco battles ov...</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>The HSE is investigating if some tobacco compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doubling down on a good hand</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>From an Irish perspective, one of the big diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dublin most expensive place to live in euro zo...</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>Spiralling accommodation costs have made Dubli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Businesses to seek instant end to lockdown and...</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>Ibec chief executive Danny McCoy will call for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Call for zero rate VAT as stores reopen; CRH U...</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>The Government should consider introducing a z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        date  \\\n",
       "0  Decathlon’s Dublin opening, tobacco battles ov...  2020-06-09   \n",
       "1                       Doubling down on a good hand  2020-06-09   \n",
       "2  Dublin most expensive place to live in euro zo...  2020-06-09   \n",
       "3  Businesses to seek instant end to lockdown and...  2020-06-08   \n",
       "4  Call for zero rate VAT as stores reopen; CRH U...  2020-06-08   \n",
       "\n",
       "                                                text  \n",
       "0  The HSE is investigating if some tobacco compa...  \n",
       "1  From an Irish perspective, one of the big diff...  \n",
       "2  Spiralling accommodation costs have made Dubli...  \n",
       "3  Ibec chief executive Danny McCoy will call for...  \n",
       "4  The Government should consider introducing a z...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "articles = pd.read_csv(\"csv/trial2.csv\")\n",
    "display(articles.head())\n",
    "# Drop all but 'date' column\n",
    "articles = articles['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use dictionaries to count frequency of adjectives of various type. We use NLTK's pos tagger to identify the adjectives amongst the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjectives\n",
      "1  -  economic 15\n",
      "2  -  last 9\n",
      "3  -  first 8\n",
      "4  -  Irish 8\n",
      "5  -  pandemic 8\n",
      "6  -  much 8\n",
      "7  -  good 8\n",
      "8  -  new 7\n",
      "9  -  financial 7\n",
      "10  -  many 7\n",
      "\n",
      "Comparative adjectives\n",
      "1  -  more 10\n",
      "2  -  costlier 2\n",
      "3  -  less 2\n",
      "4  -  lower 2\n",
      "5  -  greener 1\n",
      "6  -  easier 1\n",
      "7  -  weaker 1\n",
      "8  -  sharper 1\n",
      "9  -  clearer 1\n",
      "10  -  better 1\n",
      "\n",
      "Superlative adjectives\n",
      "1  -  latest 7\n",
      "2  -  biggest 5\n",
      "3  -  least 5\n",
      "4  -  most 3\n",
      "5  -  largest 2\n",
      "6  -  worst 2\n",
      "7  -  hardest 1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# defaultdict allows us to initialise dict to 0 values\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "\n",
    "# These disctionaries will store a count for each adjective\n",
    "# adjectives\n",
    "jj = defaultdict(int)\n",
    "# comparative adjectives\n",
    "jjr = defaultdict(int)\n",
    "# superlative adjectives\n",
    "jjs = defaultdict(int) \n",
    "\n",
    "# use regex to remove punctuation\n",
    "removePunctuation = lambda s: re.sub(r'[^\\w\\s]','',s)\n",
    "\n",
    "for i in range(len(articles)-1):\n",
    "    \n",
    "    articleText = articles[i]\n",
    "    # We ensure that articleText is a string before proceeding,\n",
    "    # this prevents errors with removePunctuation()\n",
    "    if isinstance(articleText, str):\n",
    "        articleText = removePunctuation(articleText)\n",
    "        tokenizedText = word_tokenize(articleText)\n",
    "        \n",
    "        taggedText = nltk.pos_tag(tokenizedText)\n",
    "        \n",
    "        # taggetText in the form (word, tag)\n",
    "        for pair in taggedText:\n",
    "            if(pair[1] == 'JJ'):\n",
    "                jj[pair[0]] += 1\n",
    "\n",
    "            if(pair[1] == 'JJR'):\n",
    "                jjr[pair[0]] += 1\n",
    "\n",
    "            if(pair[1] == 'JJS'):\n",
    "                jjs[pair[0]] += 1\n",
    "\n",
    "print(\"Adjectives\")\n",
    "i = 1\n",
    "for word in sorted(jj, key=jj.get, reverse=True)[:10]:\n",
    "    print(i, \" - \", word, jj[word])\n",
    "    i += 1\n",
    "    \n",
    "print(\"\\nComparative adjectives\")\n",
    "i = 1\n",
    "for word in sorted(jjr, key=jjr.get, reverse=True)[:10]:\n",
    "    print(i, \" - \", word, jjr[word])\n",
    "    i += 1\n",
    "    \n",
    "print(\"\\nSuperlative adjectives\")\n",
    "i = 1\n",
    "for word in sorted(jjs, key=jjs.get, reverse=True)[:10]:\n",
    "    print(i, \" - \", word, jjs[word])\n",
    "    i += 1\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
