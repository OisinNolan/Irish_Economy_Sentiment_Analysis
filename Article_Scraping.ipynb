{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping articles from Irish Times website\n",
    "In this notebook we scrape data about news articles published to the Irish Times' website [ https://www.irishtimes.com/ ]. We are concerned with articles tagged as *Economy* that contain the words *Irish* and *economy*, assuming that those articles are about the Irish economy.\n",
    "\n",
    "For each of the relevant articles, we want to store the **Title**, **Date** and **Text**. These features will describe each article in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "We use:\n",
    "- *requests* to request HTML code from a given URL.\n",
    "- *BeautifulSoup* to parse the HTML code received.\n",
    "- *datetime* to parse dates from strings and alter their formatting.\n",
    "- *pandas* to write our data to csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get article links\n",
    "This function takes the URL for a page of search results generated by Irish Times search feature [ https://www.irishtimes.com/search ], and returns a list of articles linked to by that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArticleLinks( url ):\n",
    "    \n",
    "    articleUrls = []\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    htmlResponse = page.text\n",
    "    \n",
    "    soup = BeautifulSoup(htmlResponse, 'html.parser')\n",
    "    # We find all divs that contain links to search result articles\n",
    "    searchResultDivs = soup.find_all(\"div\", {\"class\": \"search_items_title\"})\n",
    "    \n",
    "    for searchResultDiv in searchResultDivs:\n",
    "            spanElem = searchResultDiv.find(\"span\", {\"class\":\"h2\"})\n",
    "            # We look for the 'href' attribute of the relevant <a> tags to find the URLs\n",
    "            articleUrls.append('https://www.irishtimes.com' + spanElem.contents[0]['href'])\n",
    "    \n",
    "    return articleUrls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse articles\n",
    "\n",
    "This function takes the URL for an Irish Times article, and from its HTML extracts its title, publish date and text content. It then creates a DataFrame row containing these values and writes that to the specified CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseArticle( url ):\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    htmlResponse = page.text\n",
    "    \n",
    "    soup = BeautifulSoup(htmlResponse, 'html.parser')\n",
    "    \n",
    "    # Ensure article is not 'subscriber only'\n",
    "    subOnlyElem = soup.find(\"div\", {\"class\": \"intercept-modal\"})\n",
    "    if(subOnlyElem != None):\n",
    "        return\n",
    "    \n",
    "    # Get article title\n",
    "    headerSectionElem = soup.find(\"hgroup\")\n",
    "    titleElem = headerSectionElem.find(\"h1\")\n",
    "    titleText = titleElem.text\n",
    "    \n",
    "    # Get article date\n",
    "    timeElem = soup.find(\"time\")\n",
    "    timeText = timeElem['title']\n",
    "    if(timeText == ''):\n",
    "        timeText = timeElem.text\n",
    "    timeText = timeText[:timeText.rindex(',')]\n",
    "    dateText = datetime.datetime.strptime(timeText, '%a, %b %d, %Y').strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Get article text\n",
    "    articleElem = soup.find(\"div\", {\"class\": \"article_bodycopy\"})\n",
    "    paragraphElems = articleElem.find_all(\"p\")\n",
    "    \n",
    "    paragraphText = \"\"\n",
    "    \n",
    "    # Article text consists of a set of paragraphs, which we concatenate in paragraphText\n",
    "    for paragraphElem in paragraphElems:\n",
    "        paragraphText += paragraphElem.text \n",
    "    \n",
    "    # Make a DataFrame with these values in a row, and append that row to a csv file\n",
    "    data = [[titleText, dateText, paragraphText]]\n",
    "    df = pd.DataFrame(data, columns=['title', 'date', 'text'])\n",
    "    df.to_csv('csv/trial3.csv', mode='a', header=False, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing all available articles\n",
    "We generated links for all 1066 pages of search results, allowing us to parse all available articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n"
     ]
    }
   ],
   "source": [
    "baseUrl = \"https://www.irishtimes.com/search/search-7.4195619?q=%22irish+economy%22&toDate=14-06-2020&page=\"\n",
    "\n",
    "for i in range(902,1067 ):\n",
    "    articleLinks = getArticleLinks(baseUrl + str(i))\n",
    "    print(i)\n",
    "    for link in articleLinks:\n",
    "        try:\n",
    "            parseArticle(link)\n",
    "        except:\n",
    "            print(\"Exception\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
